# Faithfulness-between-language-Models

In many real-world natural language processing (NLP) applications, practitioners aim not only to optimize predictive performance but also to provide reliable explanations for model outputs. Feature attribution methods (FAs) offer valuable insights into how different parts of the input data contribute to the model's predictions. While previous research has focused on FA faithfulness primarily in monolingual English models, the comparison between multilingual and monolingual models remains underexplored. Through comprehensive experiments in five languages and with five popular FAs, we demonstrate that the faithfulness of FAs differs between multilingual and monolingual models. Our findings reveal that as the multilingual model size increases, the faithfulness of its FAs decreases in comparison to monolingual models. Further analysis suggests that this disparity may be influenced by differences in how the model tokenizers handle the data
